{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iceQHdrop/bioinformatic_data_mining/blob/main/ML_for_donar_finding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmZTC1lWMhI5"
      },
      "source": [
        "# ML for donar finding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEj1_5b2Mwqi",
        "outputId": "c9432e16-be8c-446e-b3c0-57b28effce66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y3MtQEWlMtoL"
      },
      "outputs": [],
      "source": [
        "! cp -r drive/MyDrive/Colab_Notebooks/bioinformatic_data_mining/dataset ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "5devSBatNNtc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, f1_score, confusion_matrix\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us1nK3-BMlu5"
      },
      "source": [
        "## 数据读取"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEoV2HUjOX11"
      },
      "source": [
        "### 设定路径名"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kfn1SA9eMp5J"
      },
      "outputs": [],
      "source": [
        "train_path = 'dataset/TrainingSet'\n",
        "test_path = 'dataset/TestingSet'    \n",
        "train_files = os.listdir(train_path)\n",
        "test_files = os.listdir(test_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfYkXEBPOghk"
      },
      "source": [
        "### 读取训练数据"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaVwTbgdRO0d"
      },
      "source": [
        "#### 定义读取函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pkCScTNaOrXx"
      },
      "outputs": [],
      "source": [
        "def LoadData(files, file_path):\n",
        "    site_seqs = []\n",
        "    normal_seqs = []\n",
        "\n",
        "    print(f'Loading data from {file_path}...')\n",
        "\n",
        "    for file in tqdm(files):\n",
        "        with open(file_path + '/' + file, 'r') as f:\n",
        "            text = f.readlines()\n",
        "            site_positions = re.findall('(\\d+)(?=,)', text[1])    # 提取位置\n",
        "            seq = ''.join(text[2:]).replace('\\n', '').lower()\n",
        "        \n",
        "            for position in site_positions:\n",
        "                site_seqs.append(seq[int(position) - 4:int(position) + 5])\n",
        "                \n",
        "            for position in range(len(seq) - 8):\n",
        "                normal_seq = seq[position:position+9]\n",
        "                \n",
        "                if normal_seq not in site_seqs and \\\n",
        "                    set(normal_seq) == {'a', 't', 'c', 'g'}:\n",
        "                    normal_seqs.append(normal_seq)\n",
        "        \n",
        "            # for num in range(4):    # 提取非位点序列\n",
        "            #     normal_position = np.random.randint(len(seq) - 9)    # 采样至倒数第九位\n",
        "            #     normal_seq = seq[normal_position - 4:normal_position + 5]\n",
        "\n",
        "            #     while normal_position in site_positions or \\\n",
        "            #         set(normal_seq) != {'a', 't', 'c', 'g'} or \\\n",
        "            #         len(normal_seq) != 9:    # 排除donar位点与'n', 'm' 等\n",
        "\n",
        "            #         normal_position = np.random.randint(len(seq) - 9)\n",
        "            #         normal_seq = seq[normal_position - 4:normal_position + 5]\n",
        "\n",
        "            #     normal_seqs.append(normal_seq)\n",
        "    \n",
        "    site_df = pd.DataFrame(list(zip(site_seqs, np.ones(len(site_seqs)))),    # 位点\n",
        "                            columns = ['Seq', 'Donar'])\n",
        "\n",
        "    normal_df = pd.DataFrame(list(zip(normal_seqs, np.zeros(len(normal_seqs)))),    # 非位点\n",
        "                              columns = ['Seq', 'Donar'])\n",
        "\n",
        "    df = pd.concat([site_df, normal_df]).reset_index(drop = True)\n",
        "\n",
        "    return df\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-50CdAQmO8Xd"
      },
      "source": [
        "#### 读取数据   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg1wJRcdRYYM",
        "outputId": "5738e173-a2b9-4d35-f38b-0266ee7057e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from dataset/TrainingSet...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 462/462 [01:43<00:00,  4.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from dataset/TestingSet...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 570/570 [00:56<00:00, 10.08it/s]\n"
          ]
        }
      ],
      "source": [
        "train_df = LoadData(train_files, train_path)\n",
        "test_df = LoadData(test_files, test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-xApIfyRdoA"
      },
      "source": [
        "## 特征提取"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRZF1CmpYeGX"
      },
      "source": [
        "### One-hot 编码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "95SVQROnSXMV",
        "outputId": "1c4763b9-7747-43c8-900e-0a8dcb86618a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1_a</th>\n",
              "      <th>1_c</th>\n",
              "      <th>1_g</th>\n",
              "      <th>1_t</th>\n",
              "      <th>2_a</th>\n",
              "      <th>2_c</th>\n",
              "      <th>2_g</th>\n",
              "      <th>2_t</th>\n",
              "      <th>3_a</th>\n",
              "      <th>3_c</th>\n",
              "      <th>...</th>\n",
              "      <th>7_g</th>\n",
              "      <th>7_t</th>\n",
              "      <th>8_a</th>\n",
              "      <th>8_c</th>\n",
              "      <th>8_g</th>\n",
              "      <th>8_t</th>\n",
              "      <th>9_a</th>\n",
              "      <th>9_c</th>\n",
              "      <th>9_g</th>\n",
              "      <th>9_t</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3212062</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3212063</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3212064</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3212065</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3212066</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3212067 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         1_a  1_c  1_g  1_t  2_a  2_c  2_g  2_t  3_a  3_c  ...  7_g  7_t  8_a  \\\n",
              "0          0    1    0    0    1    0    0    0    0    0  ...    0    0    1   \n",
              "1          1    0    0    0    0    0    0    1    0    0  ...    0    0    1   \n",
              "2          0    0    0    1    1    0    0    0    0    0  ...    0    0    1   \n",
              "3          0    0    0    1    0    1    0    0    1    0  ...    1    0    0   \n",
              "4          1    0    0    0    0    0    1    0    1    0  ...    1    0    1   \n",
              "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "3212062    0    0    1    0    0    1    0    0    0    0  ...    1    0    0   \n",
              "3212063    0    1    0    0    0    0    0    1    0    0  ...    0    0    0   \n",
              "3212064    0    0    0    1    0    0    1    0    0    0  ...    1    0    0   \n",
              "3212065    0    0    1    0    0    0    0    1    1    0  ...    0    0    0   \n",
              "3212066    0    0    0    1    1    0    0    0    0    0  ...    0    0    0   \n",
              "\n",
              "         8_c  8_g  8_t  9_a  9_c  9_g  9_t  \n",
              "0          0    0    0    0    0    1    0  \n",
              "1          0    0    0    0    0    1    0  \n",
              "2          0    0    0    0    0    1    0  \n",
              "3          0    1    0    0    0    1    0  \n",
              "4          0    0    0    0    0    1    0  \n",
              "...      ...  ...  ...  ...  ...  ...  ...  \n",
              "3212062    1    0    0    0    0    1    0  \n",
              "3212063    0    1    0    0    1    0    0  \n",
              "3212064    1    0    0    0    1    0    0  \n",
              "3212065    1    0    0    0    1    0    0  \n",
              "3212066    1    0    0    0    1    0    0  \n",
              "\n",
              "[3212067 rows x 36 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train = train_df['Seq'].str.split('', expand = True).iloc[:, 1:10]\n",
        "X_train = pd.get_dummies(X_train)\n",
        "y_train = train_df['Donar']\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "wflA7V3mSnVF",
        "outputId": "35d18b30-5cee-498f-a5d3-251616b1a575"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1702069,)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test = test_df['Seq'].str.split('', expand = True).iloc[:, 1:10]\n",
        "X_test = pd.get_dummies(X_test)\n",
        "y_test = test_df['Donar']\n",
        "X_test.head()\n",
        "y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lthgzLrMY0uL"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wJAv55lOZwIO"
      },
      "outputs": [],
      "source": [
        "clf = SVC()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6STAG9rCaE64",
        "outputId": "5b4ced54-296d-4984-b38b-1750e0310bf6"
      },
      "outputs": [],
      "source": [
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "# result_df = pd.DataFrame({'Donar': y_test, 'Pred': y_pred})\n",
        "# result_df.to_csv('SVM_test_df.csv')\n",
        "result_df = pd.read_csv('SVM_test_df.csv', index_col = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### F1-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "svm_f1 = f1_score(result_df['Donar'], result_df['Pred'])\n",
        "svm_mat = confusion_matrix(result_df['Donar'], result_df['Pred'])\n",
        "\n",
        "plt.figure(figsize = (5, 5))\n",
        "svm_hm = sns.heatmap(np.log(svm_mat), \n",
        "                        annot = svm_mat, \n",
        "                        cmap = 'YlGnBu', \n",
        "                        xticklabels = ['Pred Normal', 'Pred Donar'],\n",
        "                        yticklabels = ['Normal', 'Donar'],\n",
        "                        cbar = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqOZjHHRaKM9"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjyBBoGqcdaC"
      },
      "source": [
        "### 确定设备"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvxE6eC3acxb",
        "outputId": "1e4dcbb3-f1a6-4acb-c762-16558de47d1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model will be running on cuda.\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'The model will be running on {device}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgu6hvS-cmSu"
      },
      "source": [
        "### 定义模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dZEAXLThYDg1"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layers = nn.Sequential(nn.Conv2d(1, 10, kernel_size = 3, padding = 1, stride = 1),\n",
        "                                    nn.ReLU(True),\n",
        "                                    nn.Conv2d(10, 20, kernel_size = 3, padding = 1, stride = 1),\n",
        "                                    nn.ReLU(True),\n",
        "                                    nn.Conv2d(20, 50, kernel_size = 3, padding = 1, stride = 1),\n",
        "                                    nn.ReLU(True),\n",
        "                                    nn.Flatten(),\n",
        "                                    nn.Linear(4*9*50, 2))\n",
        "        \n",
        "    def forward(self, X):\n",
        "        X = X.view(-1, 1, 9, 4)\n",
        "        return self.layers(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz58yB4CrEeJ"
      },
      "source": [
        "### 模型结构"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "DCFT1pwjoyxP",
        "outputId": "fcbf9000-3fe0-41ee-87ff-3316e467da74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting hiddenlayer\n",
            "  Downloading hiddenlayer-0.3-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: hiddenlayer\n",
            "Successfully installed hiddenlayer-0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/data4/zhanghaohong/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:720: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  result = self._slow_forward(*input, **kwargs)\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'graphviz'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/data4/zhanghaohong/github/bioinformatic_data_mining/ML_for_donar_finding.ipynb Cell 30'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.123.145/data4/zhanghaohong/github/bioinformatic_data_mining/ML_for_donar_finding.ipynb#ch0000027vscode-remote?line=3'>4</a>\u001b[0m cnn_vis \u001b[39m=\u001b[39m CNN()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.123.145/data4/zhanghaohong/github/bioinformatic_data_mining/ML_for_donar_finding.ipynb#ch0000027vscode-remote?line=4'>5</a>\u001b[0m vis_graph \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mbuild_graph(cnn_vis, torch\u001b[39m.\u001b[39mzeros([\u001b[39m1\u001b[39m ,\u001b[39m1\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m4\u001b[39m])) \n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.123.145/data4/zhanghaohong/github/bioinformatic_data_mining/ML_for_donar_finding.ipynb#ch0000027vscode-remote?line=5'>6</a>\u001b[0m vis_graph\u001b[39m.\u001b[39;49msave(\u001b[39m'\u001b[39;49m\u001b[39mmodel_fig\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "File \u001b[0;32m/data4/zhanghaohong/anaconda3/envs/torch/lib/python3.8/site-packages/hiddenlayer/graph.py:363\u001b[0m, in \u001b[0;36mGraph.save\u001b[0;34m(self, path, format)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave\u001b[39m(\u001b[39mself\u001b[39m, path, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpdf\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[39m# TODO: assert on acceptable format values\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     dot \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_dot()\n\u001b[1;32m    364\u001b[0m     dot\u001b[39m.\u001b[39mformat \u001b[39m=\u001b[39m \u001b[39mformat\u001b[39m\n\u001b[1;32m    365\u001b[0m     directory, file_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplit(path)\n",
            "File \u001b[0;32m/data4/zhanghaohong/anaconda3/envs/torch/lib/python3.8/site-packages/hiddenlayer/graph.py:316\u001b[0m, in \u001b[0;36mGraph.build_dot\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_dot\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    312\u001b[0m     \u001b[39m\"\"\"Generate a GraphViz Dot graph.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \n\u001b[1;32m    314\u001b[0m \u001b[39m    Returns a GraphViz Digraph object.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgraphviz\u001b[39;00m \u001b[39mimport\u001b[39;00m Digraph\n\u001b[1;32m    318\u001b[0m     \u001b[39m# Build GraphViz Digraph\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     dot \u001b[39m=\u001b[39m Digraph()\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
          ]
        }
      ],
      "source": [
        "! pip install hiddenlayer\n",
        "import hiddenlayer as h\n",
        "\n",
        "cnn_vis = CNN()\n",
        "vis_graph = h.build_graph(cnn_vis, torch.zeros([1 ,1, 9, 4])) \n",
        "vis_graph.save('model_fig')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BJjVlNncsG0"
      },
      "source": [
        "### 重新定义数据特征表示"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kXAHymLbUpx"
      },
      "source": [
        "#### 定义编码函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NRFwkW3TczXz"
      },
      "outputs": [],
      "source": [
        "def OneHot(seq):\n",
        "    base_dict = {'a': 0, 't': 1, 'c': 2, 'g': 3}\n",
        "    seq_list = [base_dict[base] for base in seq]\n",
        "    seq_tensor = torch.tensor(seq_list)\n",
        "    return F.one_hot(seq_tensor).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek3OuZMIa7aE"
      },
      "source": [
        "#### 编码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-Hf_I31Wffx",
        "outputId": "c32f4382-5e8e-4240-da78-08f4f78d7b1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [0., 0., 0., 1.]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_cnn = torch.tensor(train_df['Seq'].apply(OneHot).values.tolist(), \n",
        "                           dtype = torch.float)\n",
        "X_test_cnn = torch.tensor(test_df['Seq'].apply(OneHot).values.tolist(), \n",
        "                          dtype = torch.float)\n",
        "y_train_cnn = torch.tensor(train_df['Donar'])\n",
        "y_test_cnn = torch.tensor(test_df['Donar'])\n",
        "X_train_cnn[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY0XSlOLfUUZ"
      },
      "source": [
        "### 装入DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1FhKmiClfdQL"
      },
      "outputs": [],
      "source": [
        "whole_train_set = TensorDataset(X_train_cnn, y_train_cnn)\n",
        "test_set = TensorDataset(X_test_cnn, y_test_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMSWb0tboqtP"
      },
      "source": [
        "### 定义训练函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "c0dV6qShaMpi"
      },
      "outputs": [],
      "source": [
        "def train(whole_train_set):\n",
        "    train_set, valid_set = random_split(whole_train_set, [int(0.8*len(whole_train_set)), len(whole_train_set) - int(0.8*len(whole_train_set))])\n",
        "    train_loader = DataLoader(train_set, batch_size = 500, shuffle = True)\n",
        "    # valid_loader = DataLoader(valid_set, batch_size = 500, shuffle = True)\n",
        "    \n",
        "    model = CNN()\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "    best_f1 = 0.0\n",
        "    \n",
        "    for epoch in range(200):\n",
        "        running_train_loss = 0.0  \n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            X = data[0].to(device)\n",
        "            y = data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = model(X)  \n",
        "            loss = criterion(outputs, y.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_train_loss += loss\n",
        "        \n",
        "        train_loss = running_train_loss/len(train_loader)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            \n",
        "            X = valid_set[:][0].to(device)\n",
        "            y = valid_set[:][1].to(device)\n",
        "            outputs = model(X)\n",
        "            val_loss = criterion(outputs, y.long())\n",
        "            _, y_pred = torch.max(outputs, dim = 1)\n",
        "            f1 = f1_score(y.cpu().detach().numpy(), y_pred.cpu().detach().numpy())        \n",
        "        \n",
        "        if f1 > best_f1:\n",
        "            torch.save(model.state_dict(), f'./best_model.pth')\n",
        "            print(f'The model has been saved for the best F1-score {f1}')\n",
        "            best_f1 = f1\n",
        "        \n",
        "        if epoch == 0:\n",
        "            print(f'The model is working fine! F1-score: {f1}')\n",
        "\n",
        "        if (epoch + 1)%10 == 0:\n",
        "            print(f'Completed training epoch', epoch + 1, 'Training Loss is: %.4f' %train_loss, 'Validation Loss is: %.4f' %val_loss, 'f1-score is {f1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy0JCTW5otyP"
      },
      "source": [
        "### 训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoEQrrHlowmd",
        "outputId": "ff2700c1-9cca-4be9-a375-ce557dac1397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model is working fine! F1-score: 0.0\n",
            "The model has been saved for the best F1-score 0.36393442622950817\n",
            "The model has been saved for the best F1-score 0.47647058823529415\n",
            "The model has been saved for the best F1-score 0.5200553250345781\n",
            "The model has been saved for the best F1-score 0.56158940397351\n",
            "The model has been saved for the best F1-score 0.5809768637532133\n",
            "Completed training epoch 10 Training Loss is: 0.0015 Validation Loss is: 0.0015 f1-score is {f1}\n",
            "The model has been saved for the best F1-score 0.5985037406483791\n",
            "The model has been saved for the best F1-score 0.6025\n",
            "The model has been saved for the best F1-score 0.6072289156626506\n",
            "The model has been saved for the best F1-score 0.6096385542168674\n",
            "The model has been saved for the best F1-score 0.6108374384236454\n",
            "Completed training epoch 20 Training Loss is: 0.0014 Validation Loss is: 0.0014 f1-score is {f1}\n",
            "The model has been saved for the best F1-score 0.6121437422552665\n",
            "The model has been saved for the best F1-score 0.6264775413711584\n",
            "The model has been saved for the best F1-score 0.6306098964326813\n",
            "The model has been saved for the best F1-score 0.6312056737588652\n",
            "The model has been saved for the best F1-score 0.6319526627218934\n",
            "The model has been saved for the best F1-score 0.6342042755344419\n",
            "Completed training epoch 30 Training Loss is: 0.0014 Validation Loss is: 0.0014 f1-score is {f1}\n",
            "The model has been saved for the best F1-score 0.6348448687350835\n",
            "The model has been saved for the best F1-score 0.6351829988193625\n",
            "The model has been saved for the best F1-score 0.6367924528301887\n",
            "Completed training epoch 40 Training Loss is: 0.0014 Validation Loss is: 0.0014 f1-score is {f1}\n",
            "Completed training epoch 50 Training Loss is: 0.0014 Validation Loss is: 0.0014 f1-score is {f1}\n",
            "The model has been saved for the best F1-score 0.6429418742586003\n",
            "Completed training epoch 60 Training Loss is: 0.0014 Validation Loss is: 0.0014 f1-score is {f1}\n",
            "The model has been saved for the best F1-score 0.6453143534994069\n",
            "Completed training epoch 70 Training Loss is: 0.0013 Validation Loss is: 0.0014 f1-score is {f1}\n",
            "The model has been saved for the best F1-score 0.6477541371158393\n",
            "The model has been saved for the best F1-score 0.6501182033096927\n",
            "Completed training epoch 80 Training Loss is: 0.0013 Validation Loss is: 0.0014 f1-score is {f1}\n",
            "Completed training epoch 90 Training Loss is: 0.0013 Validation Loss is: 0.0014 f1-score is {f1}\n",
            "The model has been saved for the best F1-score 0.6507177033492823\n",
            "Completed training epoch 100 Training Loss is: 0.0013 Validation Loss is: 0.0013 f1-score is {f1}\n",
            "The model has been saved for the best F1-score 0.6507747318235996\n",
            "The model has been saved for the best F1-score 0.6533018867924527\n",
            "The model has been saved for the best F1-score 0.6548881036513545\n",
            "Completed training epoch 110 Training Loss is: 0.0013 Validation Loss is: 0.0013 f1-score is {f1}\n",
            "The model has been saved for the best F1-score 0.6564705882352941\n",
            "Completed training epoch 120 Training Loss is: 0.0013 Validation Loss is: 0.0013 f1-score is {f1}\n",
            "Completed training epoch 130 Training Loss is: 0.0013 Validation Loss is: 0.0014 f1-score is {f1}\n",
            "The model has been saved for the best F1-score 0.6682134570765661\n",
            "Completed training epoch 140 Training Loss is: 0.0013 Validation Loss is: 0.0013 f1-score is {f1}\n",
            "The model has been saved for the best F1-score 0.6787741203178206\n",
            "Completed training epoch 150 Training Loss is: 0.0013 Validation Loss is: 0.0013 f1-score is {f1}\n",
            "The model has been saved for the best F1-score 0.683684794672586\n",
            "Completed training epoch 160 Training Loss is: 0.0013 Validation Loss is: 0.0013 f1-score is {f1}\n",
            "Completed training epoch 170 Training Loss is: 0.0013 Validation Loss is: 0.0013 f1-score is {f1}\n",
            "Completed training epoch 180 Training Loss is: 0.0013 Validation Loss is: 0.0013 f1-score is {f1}\n",
            "Completed training epoch 190 Training Loss is: 0.0013 Validation Loss is: 0.0013 f1-score is {f1}\n",
            "Completed training epoch 200 Training Loss is: 0.0013 Validation Loss is: 0.0013 f1-score is {f1}\n"
          ]
        }
      ],
      "source": [
        "train(whole_train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "jdANy0Jpqbz9"
      },
      "outputs": [],
      "source": [
        "def test(test_set):\n",
        "    model = CNN()\n",
        "    model.to('cpu')\n",
        "    model.load_state_dict(torch.load(f'./best_model.pth'))\n",
        "    model.eval()\n",
        "    \n",
        "    X = test_set[:][0].to('cpu')\n",
        "    y = test_set[:][1].to('cpu')\n",
        "    \n",
        "    y_pred = F.softmax(model(X), 1)[:, 1]\n",
        "    return pd.DataFrame({'Donar': y.cpu().detach().numpy(), 'Score': y_pred.cpu().detach().numpy()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd_PeEObqhN4",
        "outputId": "ce337d63-9590-4694-8b4a-0620a6d88a1d"
      },
      "outputs": [],
      "source": [
        "result_df = test(test_set)\n",
        "result_df.to_csv('CNN_test_df.csv')\n",
        "result_df = pd.read_csv('CNN_test_df.csv', index_col = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.758697467297523,\n",
              " array([[1699839,     151],\n",
              "        [    716,    1363]]))"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn_f1 =  f1_score(result_df['Donar'], result_df['Score'].apply(lambda x: 1 if x > 0.5 else 0))\n",
        "cnn_mat = confusion_matrix(result_df['Donar'], result_df['Score'].apply(lambda x: 1 if x > 0.5 else 0))\n",
        "cnn_f1, cnn_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize = (5, 5))\n",
        "cnn_hm = sns.heatmap(np.log(cnn_mat), \n",
        "                        annot = cnn_mat, \n",
        "                        cmap = 'YlGnBu', \n",
        "                        xticklabels = ['Pred Normal', 'Pred Donar'],\n",
        "                        yticklabels = ['Normal', 'Donar'],\n",
        "                        cbar = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPfE5hDVzOyUGdolur2khyc",
      "collapsed_sections": [],
      "include_colab_link": true,
      "mount_file_id": "1gm070IemrSmiZisRU7DNIut5ExUM3yoI",
      "name": "ML_for_donar_finding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('torch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "9ff2abf7b7cf8a1b21908a8a7b42aaf8c083e7b836cc07037792e5e51d8c906d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
